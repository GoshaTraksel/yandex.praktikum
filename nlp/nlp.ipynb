{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание проекта\n",
    "\n",
    "В нашем распоряжении датасет с размечеными комментариями от пользователей `toxic_comments.csv`. Основная задача проекта: `Обучить модель классифицировать комментарии на негативные и позитивные`. Условие выполнения задачи: `Построить модель со значением метрики качества F1 не меньше 0.75`. В ноутбуке я использовал предобученноую модель BERT, код которой можно посмотреть в моём ноутбуке на Google Colab: [Модель BERT в Google Colab](https://colab.research.google.com/drive/1iocPsw7WVDOo1_94PXHoloRzuiwN04DX 'Модель BERT в Google Colab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорты и загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from joblib import dump, load\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import f1_score, mean_absolute_error as mae\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 2)\n",
      "(450, 768)\n",
      "(450,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')                                # full dataframe\n",
    "X_bert_balanced = np.array(pd.read_csv('/datasets/features_bert_balanced.csv'))   # BERT features with class balance\n",
    "y_bert_balanced = pd.read_csv('/datasets/df_bert_balanced.csv')['toxic']          # BERT target with class balance\n",
    "\n",
    "# display\n",
    "print(data.shape)                # full dataframe\n",
    "print(X_bert_balanced.shape)     # BERT features with class balance\n",
    "print(y_bert_balanced.shape)     # BERT target with class balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С BERT я работал в Google Colab. Посмотреть ноутбук можно по ссылке:\n",
    "\n",
    "[Модель BERT в Google Colab](https://colab.research.google.com/drive/1iocPsw7WVDOo1_94PXHoloRzuiwN04DX 'Модель BERT в Google Colab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>daww he matches this background colour im seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man im really not trying to edit war its j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i cant make any real suggestions on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                          text_clean  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  daww he matches this background colour im seem...  \n",
       "2  hey man im really not trying to edit war its j...  \n",
       "3  more i cant make any real suggestions on impro...  \n",
       "4  you sir are my hero any chance you remember wh...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean(text):\n",
    "    \n",
    "    text = text.lower()    \n",
    "    text = re.sub(r\"(?:\\n|\\r)\", \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z ]+\", \"\", text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "data['text_clean'] = data['text'].apply(clean)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a96fa3a52b46cd8a76cb24ad4494ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=159571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "def lemmatize(text):\n",
    "    temp = []\n",
    "    for token in nlp(text):\n",
    "        if token.is_stop == False:\n",
    "            temp.append(token.lemma_)\n",
    "    return \" \".join(temp)\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "data['text_lemma'] = data['text_clean'].progress_apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(data, '/datasets/toxic_comments_ppg.csv')\n",
    "data = load('/datasets/toxic_comments_ppg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я сохраню предобработанные данные в файл для последующей загрузки, чтобы избежать повторного процесса лемматизации при повторном запуске ноутбука."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Баланс в классах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.898321\n",
      "1    0.101679\n",
      "Name: toxic, dtype: float64\n",
      "1    0.555556\n",
      "0    0.444444\n",
      "Name: toxic, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# посмотрим на баланс классов в таргете\n",
    "print(data['toxic'].value_counts(normalize=True))    # full dataframe\n",
    "print(y_bert_balanced.value_counts(normalize=True))  # BERT target with class balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для балансировки классов я буду использовать технику увеличения выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(X, y, repeat):\n",
    "    X_zeros = X[y == 0]\n",
    "    X_ones = X[y == 1]\n",
    "    y_zeros = y[y == 0]    \n",
    "    y_ones = y[y == 1]    \n",
    "    \n",
    "    X_upsampled = pd.concat(\n",
    "        [X_zeros] + [X_ones] * repeat)    \n",
    "    y_upsampled = pd.concat(\n",
    "        [y_zeros] + [y_ones] * repeat)    \n",
    "    X_upsampled, y_upsampled = shuffle(        \n",
    "        X_upsampled, y_upsampled, random_state=42) \n",
    "    \n",
    "    return X_upsampled, y_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.898253\n",
      "1    0.101747\n",
      "Name: toxic, dtype: float64\n",
      "0    0.595608\n",
      "1    0.404392\n",
      "Name: toxic, dtype: float64\n",
      "(180508,) (180508,)\n",
      "(39893,) (39893,)\n"
     ]
    }
   ],
   "source": [
    "X = data['text_lemma']\n",
    "y = data['toxic']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=42)\n",
    "\n",
    "X_train, y_train = upsample(X_train, y_train, repeat=6)\n",
    "\n",
    "print(y_train.value_counts(normalize=True))    # train class balance info\n",
    "print(y_test.value_counts(normalize=True))     # test class balance info\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit + TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(ngram_range=(1, 1))),\n",
    "    ('model', LogisticRegression(max_iter=150, solver='liblinear', random_state=42))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'vectorizer__ngram_range': [(1, 1), (3, 1), (5, 2)],\n",
    "    'model': [LogisticRegression(max_iter=150, solver='liblinear', random_state=42)],\n",
    "    'model__C': [1, 5, 10, 25],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=params, scoring='f1', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=25, max_iter=150, random_state=42,\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model': LogisticRegression(C=25, max_iter=150, random_state=42, solver='liblinear'),\n",
       " 'model__C': 25,\n",
       " 'vectorizer__ngram_range': (1, 1)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9735486184306842"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid.fit(X_train, y_train)\n",
    "display(grid.best_estimator_, grid.best_params_, grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7675321523901966"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = grid.best_estimator_\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "f1_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью подбора параметров нам удалось достич метрики качества F1 = 0.75. Посмотрим как работает Logit + BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bert, X_test_bert = train_test_split(X_bert_balanced, test_size=.5, random_state=42)\n",
    "y_train_bert, y_test_bert = train_test_split(y_bert_balanced, test_size=.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('model', LogisticRegression(max_iter=150, solver='liblinear', random_state=42))\n",
    "])\n",
    "\n",
    "params = [\n",
    "        {\n",
    "            'model': [LogisticRegression(max_iter=1000, solver='liblinear', \\\n",
    "                                         random_state=42, class_weight='balanced')],\n",
    "            'model__C': [1, 5, 10, 25],\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=params, scoring='f1', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('model',\n",
       "                 LogisticRegression(C=1, class_weight='balanced', max_iter=1000,\n",
       "                                    random_state=42, solver='liblinear'))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model': LogisticRegression(C=1, class_weight='balanced', max_iter=1000, random_state=42,\n",
       "                    solver='liblinear'),\n",
       " 'model__C': 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8602532658783453"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 487 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid.fit(X_train_bert, y_train_bert)\n",
    "display(grid.best_estimator_, grid.best_params_, grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8515625"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert = grid.best_estimator_\n",
    "bert.fit(X_train_bert, y_train_bert)\n",
    "predictions = bert.predict(X_test_bert)\n",
    "f1_score(predictions, y_test_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Общий вывод\n",
    "\n",
    "У нас получилось достич нужного рейтинга F1. Модель Logit + BERT показала результат F1 = 0.86, это лучше чем Logit + TF IDF F1 = 0.76 на 0.10!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
